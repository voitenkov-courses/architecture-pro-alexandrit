# Архитектурное решение по логированию

## список необходимых логов с уровнем INFO

|Система|Что логируем|Какие данные|
|-------|------------|------------|
|Shop API|Статус заказа|Время, ID сессии, ID покупателя, ID заказа, статус|
|Shop API|Сессии пользователей|Время, ID сессии, ID покупателя, вход/выход, IP, User-Agent|
|Shop API|Работа с очередью|Время, ID заказа, операция (чтение/запись), количество байт|
|CRM API|Сессии пользователей|Время, ID сессии, ID покупателя, вход/выход, IP, User-Agent|
|CRM API|Действия с заказами|Время, ID сессии, ID пользователя, ID заказа, операция, измененные данные|
|Partner API|Запросы партнеров|Время, ID партнера, метод, эндпойнт, запрос, код ответа, IP, User-Agent|
|Partner API|Работа с очередью|Время, ID заказа, операция (чтение/запись), количество байт|
|MES API|Сессии пользователей|Время, ID сессии, ID оператора, вход/выход, IP, User-Agent|
|MES API|Действия с заказами|Время, ID сессии, ID оператора, ID заказа, операция, измененные данные|
|MES API|Работа с очередью|Время, ID заказа, операция (чтение/запись), количество байт|

Также будут логироваться события с другими уровнями логирования:
* FATAL, ERROR - проблемы, связанные с ошибками сервисов и межсервисных взаимодействий, ошибки БД
* WARN - нестандартные ситуации сервисов или действий пользователя (например, ошибки аутентификации)

и при необходимости:
* DEBUG и TRACE - детальное логирование всех действий в сервисах, например, запросы к БД, вызовы промежуточных функций обработки данных.

## Мотивация

Внедрение логирования позволит повлиять на следующие технические и бизнес-метрики:

* Response time (latency)
* Number of HTTP 500
* количество потерянных заказов
* среднее, минимальное и максимальное время обработки заказа
* среднее, минимальное и максимальное время нахождения заказа в определенном статусе

В первую очередь реализуем логирование для сервисов Shop API и Partner API и CRM API, поскольку надо решить проблему с потерей заказов.

## Компромиссы

Аналогично трейсингу реализация логирования в MES будет более трудозатратным, так как этот сервис изначально разрабатывался в другой компании. Тем не менее для полноты картины его надо реазовать, возможно в последнюю очередь при наличии ресурсов.

## Предлагаемое решение

Так как в системе всего 4 сервиса, использовать стек ELK будет несколько накладно по ресурсам, тем более никакой сложной обработки или парсинга логов не требуется. Поэтому для сбора логов будем использовать стек PLGT от Grafana Labs, а именно:
* Promtail - агент на узлах для сбора логов
* Loki - для хранения логов
* Grafana - для визуализации
* Tempo - для распределенного трейсинга

Плюсами являются:
* Нетребовательность к ресурсам и более простая архитектура, в отличие от решения ELK
* Распределенный трейсинг в одном комплексном решении от одного вендора
* Можно в эту же Grafana интегрировать Prometheus/Alertmanager для мониторинга и алертинга. 

Минусы:
* контент не индексируется, индексируются только метки, поиск будет медленней, по сравнению с Elasticsearch, но у нас нет требований к системе логирования как к поисковому движку 

Доработки по безопасности:
* Доступ к системе логирования будет через VPN-группы определенным пользователям.
* Дополнительно потребуется развернуть реверс-прокси, например на базе NGINX, для аутентификации пользователей.

Политики хранения:
* Отдельный индекс для каждого сервиса для возможности масштабирования и запаса по производительности
* Время хранения - 3 месяца
* Объем базы. Cloud Loki позволяет обрабатывать 1,25 ПВ в месяц. У нас пока точных данныхь по трафику нет, но явно будет меньше и Loki справится, вопрос будет к инфраструктуре. Предлагаю развернуть PoC-стенд для оценки объема БД и требований к производительности Loki
* Best practice - 10 MB/s на 1 Loki Ingestor, исходя из этой величины будем рассчитывать количество Ingestor
* Replication factor - 3 по дефолту и 3 ноды для Loki минимум по 1 Ingestor на ноду, количество Ingestor можно увеличить.
* Для производительности и экономии можно разделить процессы чтения и записи, чтобы мы могли запустить, например, более дискозависимые процессы на одном «железе», а менее дискозависимые на другом (SSD - Simple Scalable Deployment). Точно так же нужно поставить прокси перед всеми инстансами, который будет проксировать: запросы на запись на узлы записи, остальные запросы на узлы с чтением
* Хранить логи можно на S3-бэкенде, такая опция есть в облаках, объем не ограничен, стоимость низкая, георезервирование из коробки.
* На перспективу лучше перевести сервисы в Kubernetes, соответственно, инсталляция Loki при этом будет в Microservices mode — более развёрнутый путь, когда мы каждый компонент Loki (distributor, storage, ingestors) запускаем самостоятельно.

### Архитектура решения по наблюдаемости

Диаграмма контейнеров системы с учетом доработок изображена на следующей схеме, зеленым цветом выделены новые контейнеры:

![alexandrit-c4](jewerly_c4_model_logging.png)

### Компоненты решения по наблюдаемости

В сервисы интегрированы:

* OTEL SDK - для сбора трейсов
* Prometheus Client - для экспорта метрик (есть клиент для .Net)

На нодах запущены:

* Promtail для сбора логов сервисов

В отдельных сервисах запущены:

* Prometheus - сбор и хранение метрик (метрики хранятся во встроенной TSDB)
* Tempo - сбор и визуализация трейсов (трейсы хранятся на S3-хранилище)
* Loki - хранение и визуализация логов (логи хранятся во встроенной базе данных или S3-хранилище)
* Grafana - визуализация логов и метрик
* NGINX - аутентификация доступа к Grafana, балансировка

## Система анализа логов

Для поиска аномалий в Loki можно настроить алертинг на увеличение количества записей в логах выше среднего или порогового, например можно определить DDoS-атаку, если количество запросов на API стало измерятся тысячами RPS. Для поиска других аномалий придется использовать другие решения, например OpenSearch, там уже есть функционал Anomaly Detector, или Splunk, но он в бесплатной версии ограничен объемом логов.

## Рассмотренные варианты

|Критерий|Elasticsearch|OpenSearch|Splunk|Loki|
|--------|-------------|----------|------|----|
|Лицензия|Elastic License|Apache License, Version 2.0|Проприетарная|GNU Affero GPL|
|Требовательность к ресурсам|Высокая|Высокая|Высокая|Низкая|
|Скорость поиска|Высокая|Высокая|Высокая|Низкая|
|Репликация|да|да|да|да|
|Встроенная аутентификация|да|да|да|нет|
|Встроенная авторизация|да|да|да|нет|
|Сложность настройки|Высокая|Высокая|Средняя|Низкая|
|Дэшборд|Kibana|OpenDashboard|Встроен|Grafana|
|Язык запросов|Query DSL, KQL|Query DSL|LogQL|SPL|
|Поиск аномалий|да|да|да|нет|
|В стек также входят|Logstash, Kibana|Logstash, OpenDashboard|Один продукт|Grafana, Tempo, Promtail|
|Функциональность стека вцелом|высокая|средняя|высокая|низкая|
|Ограничения функциональности бесплатной версии|высокая|все бесплатно|по трафику|все бесплатно|